## 搜索算法

### 广度优先算法（BFS）

通常在cost为1时使用，该算法寻到第一最近节点。

算法过程

```
1.将一个节点放入队列中
2.查看队列，如果队列不为空，提取一个节点；若为空，结束算法
3.查看提取出来的节点是否有邻近节点，并检查是否是GOAL
	· 如果是，返回结果
	· 如果不是，将该节点的邻近节点加入队列（FIFO）
4.回到步骤2
```

时间复杂度：

时间： O（V + E）

空间：O（V）在最坏的情况下，将所有节点都加入队列中

### 最小代价搜索（UCS）

适用于路径cost不相等的情况，是BFS的一种拓展

算法过程

```
1.初始化：从初始节点开始，将其加入到一个优先队列（priority queue），这个优先队列按照从初始节点到当前节点的路径代价进行排序
2.
```

### 深度优先搜索（DFS）

该算法沿着树的深度遍历树的节点，尽可能深得搜索树的分支，直到该分支的末端节点。当该分支完成搜索完以后，返回初始节点，进入下一条分支，遵循LIFO队列，即stack

算法过程

```
1.选择一个节点，标记为已访问。
2.以递归的方式访问该节点的邻近节点
3.当一个节点没有邻近节点时，回溯到上一个节点，访问其他的邻近节点。直到回到初始节点
```

应用：

- 寻找图中所有连通分量
- 拓扑排序
- 寻找图中的环
- 路径查找问题（问题允许非最短路径时）
- 解决迷宫，迷宫生成问题

缺点：当一条分支的节点趋于无穷大时，可能永远无法找到GOAL或寻找代价太大

### 深度限制算法（DLS）

该算法时DFS的一种优化算法，在搜索时加入了一个深度限制，防止陷入无止尽的搜索或大代价搜索

算法过程：

```
1.开始：从起始节点开始，将其设为当前节点，且设置深度限制 L
2.检查深度：如果当前节点的深度等于L，则停止在该节点的进一步搜索（不考虑当前节点的子节点）
3.拓展节点：
 - 对当前节点，检查每个子节点
 - 如果子节点是GOAL，搜索成功结束
 - 如果子节点不是GOAL，且深度 < L，则继续对每个子节点应用DLS算法
 4.回溯：如果所有子节点被检查过，且没有找到目标节点，回溯到上一级节点
 5.结束：如果搜索树中的所有节点都在深度L之内被访问且没有找到目标节点，搜索失败。需要增加L深度
```

### 迭代加深搜索（IDS）

结合了深度优先搜索（DFS）的空间效率和广度搜索（BFS）最短路径的能力。

在每次迭代后，增加L的值

算法过程

```
1.初始化深度限制：L = 0
2.执行DLS：根据L指，执行DLS，如果找到目标，则立即返回，如果没有找到，L = L + 1
3.重复2，直到找到目标
4.终止条件：为L设定一个范围，若超过该范围，终止算法
```

特点和应用：

- 完备性：IDS是完备的，意味着如果目标存在于搜索空间中，IDS始终会找到GOAL
- 最优性：与BFS相比，当GOAL处于同一个深度时，IDS的找到GOAL的效率优于BFS，因为BFS需要遍历每一个节点，而IDS通过一个分支一个分支的访问，效率更高，但在情况最差的情况，即节点在底部的最右侧，效率相同。

### 贪心最优先搜索（Greedy Best First Search）

利用一个启发式函数（Heuristic）来估计当前节点到目标节点的距离，然后选择估计距离最小的节点作为下一步的移动，一直重复该过程直到 找到目标节点 或 没有其他可访问节点

算法过程

```
1.初始化：将起始节点放入一个开放列表中（通常是一个优先队列）
2.循环执行，直到找到目标或没有更多的节点可访问：
- 从开发列表中选择一个估计成本（从当前节点到目标节点的估计距离）最小的节点作为当前节点
- 检查当前节点是否为GOAL节点，如果是，返回
- 将当前节点从开放列表移除，将其加入关闭列表（已访问过的节点）
- 对当前节点的邻近节点进行评估，计算邻近节点的成本，计算后如果邻近节点不在关闭列表中，则加入开放列表
```

优点：

通常比简单的宽度优先搜索或深度优先搜索快，因为引用了启发式信息来引导搜索方向

缺点：

并不能总是找到最短路径，因为它可能过早的引导到看起来像是最近的路径，但实际上是比较远的路径。这意味着，贪心最优先搜索不保证找到解决方案。

### A* 算法

A*算法也是通过启发式函数（heuristc）来估计从当前节点到终点的距离，同时结合了广度优先搜索的全面性和贪心最优先搜索的效率。

算法过程

```
1.初始化：将起始节点加入到开放列表中（一个优先队列），该列表用于存储待考察的节点
2. 循环下列步骤，直到找到目标节点或放开列表为空：
- 从开放列表中，选择具有最低 f(n) = g(n) + h(n) 值的节点作为当前节点，其中：
	g(n): 从起始点到当前节点的实际成本
	h(n): 当前节点到目标节点的启发式估计成本
	f(n): 节点的总估计成本
- 将当前节点移除开放列表，并加入到关闭列表（存储已经展开过的节点集合）
- 对当前节点的每一个邻居节点：
	- 如果邻居节点在关闭列表中，则忽略该节点
	- 如果邻居节点不在关闭列表中，将其添加到开放列表中，并计算g(n),h(n),f(n) 的值，设置当前节点为邻居节点的父节点
	- 如果邻居节点已经在开放列表中，这意味着已经找到一条从起始点到该节点的路径。比较新路径于旧路径，将具有更低的g(n)值的路径设为父节点
3. 重复这个过程，直到：
	- 目标节点被添加到关闭列表中，这意味着找到了路径
	- 开放列表为空，这意味着没有找到路径，则无解
```

完备性： 如果问题至少存在一个解，A*搜索保证能够找到一个解

最优性：在启发式函数满足的一定条件下，A*搜索保证能够找到最短路径

效率：A*搜索通常比其他的简单搜索算法更快，因为算法是有依据性的选择节点，而不是向广度优先搜索遍历大部分节点

#### 启发式函数的一致性 Consistente

启发式函数的一致性，确保了在寻路过程中，不会因为启发式函数值的不准确而导致寻路的跳跃性，即选择一条不是最优解的路径

对于任何节点 **n**和后继节点**n'**,**e**为他们链接路径的。

**n**的启发式成本 <= **n'**的启发式成本 + 真实成本（n，n'）

h（n） <= h（n'） + cost（n，n'）

#### 可采纳性 Ammisibile

一个启发式函数对图中的所有节点，都不会高估该节点到达目标节点的实际最小成本，被认为是可采纳的。

对于任意节点n，它的启发式函数值 <= n节点到目标节点的实际最短路径

即：h（n） <= cost (n, GOAL)

当一个启发式函数被认为是可采纳时，那么A*搜索算法一定能够找到一条路径

Consistency -> admissible

一致性是可采纳性的一个加强版。

#### 曼哈顿距离

```
D曼哈顿 = |x1 - x2| + |y1 - y2|
```

#### 欧几里得距离

$$
D欧几里得 = \def\var#1{(#1_1-#1_2)^2}
\sqrt{\var x+\var y}
$$

欧几里得vs曼哈顿

欧几里得：两点之间直线段距离

曼哈顿：横纵坐标最小移动距离

一般情况下倾向于使用曼哈顿

### 局部搜索算法

#### Hill-Climbing算法

该算法在一个解空间内，试图寻找比当前状态更好的解，当更新完新的解后，无法回溯到上一个解。

算法过程

```
1.初始状态：选择一个初始解作为起点
2.邻居评估：在当前解的邻居内找到一个更优的解（在解局部最大/小问题中，更新值更大/小的解）
3.移动决策：
 - 如果找到了一个更好的邻居，则移动到哪个邻居并更新当前的解
 - 如果周围没有更好的邻居，算法停止，因为它可能已经找到了一个局部最值
4.重复以上步骤，直到达到停止条件，通常为找不到更好的邻居，即更优解
```

#### 模拟退火算法Simulate Annealing

是一种概率型优化算法，









